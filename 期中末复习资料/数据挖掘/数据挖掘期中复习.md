# 数据挖掘原理与算法期中复习

>作者：cqq
>
>整理时间：2023-11-29
>
>最近更新时间：2023-11-30



### 考试题型与提纲

**题型：**

1. 填空
2. 选择
3. 名词解释
   - 参考释义部分
4. 英汉互译
   - 参考术语部分
5. 简答题
   - 简述数据库中知识发现（KDD）阶梯处理过程模型。
   - 知识发现（KDD）一般包含哪些基本阶段？简述各阶段的特点。
   - 事务数据库中关联规则挖掘主要包括哪两个主要步骤？各步骤的主要任务和目标是什么？
   - 简述***算法的原理和步骤。
   - 简述时间序列挖掘的含义、意义、分类及其主要任务。
   - 简述空间数据挖掘的含义、意义、分类及其主要任务。
   - 简述Web挖掘的含义、意义、分类及其主要任务。
6. 证明

**说明**

> ★为复习重点，加粗为知识提炼；本复习资料主要用于概念记忆与算法步骤和伪代码的记忆，即侧重于记忆部分，对于算法的理解和例题见资料中标出的课本相对应的页码；练手的题目可参考课本例题、课后习题和往年试卷考题。

------



### 术语

1. 重点掌握★
   - Data Mining：数据挖掘
   - Artificial Intelligence：人工智能
   - Knowledge Discovery：知识发现
   - OLAP（Online Analytical Process）：在线分析处理
   - Association Rule：关联规则
   - Maximal Frequent ItemSet：最大频繁项集
   - Data Classification：数据分类
   - Decision Tree：决策树
   - k-Nearest Neighbors：k最近邻
   - Clustering：聚类
   - Sequential Mining：序列挖掘
   - Web Content Mining：Web内容挖掘
   - Web Structure Mining：Web结构挖掘
   - Time Series：时间序列
   - Geographic Information System：地理信息系统
2. 补充
   - Decision Support：决策支持
   - Usage Mining：访问挖掘
   - Link Mining：链接挖掘
   - Data Visualization：数据可视化
   - Information Retrieval：信息检索
   - OLAP（Online Analytical Mining）：在线分析挖掘

------



### 释义

1. 重点掌握★

   - <u>***数据挖掘***</u>：定义有广义和狭义之分。从广义的观点，数据挖掘是从大型数据集中**挖掘隐含在其中的、人们事先不知道的、对决策有用的知识的**完整过程。从狭义的观点出发，我们定义数据挖掘从特定形式的数据集中提炼知识的过程。
   - <u>***频繁项目集***</u>：是指**出现频率高的项目对应的集合**，反映交易数据库中项目出现的频度信息。挖掘频繁项目集是关联规则挖掘的基础，许多关联规则挖掘方法是基于频繁项目集发现的。
   - <u>***分类***</u>：可以看作是**从数据库到一组预先定义的、非交叠的类别的映射**。数据挖掘中分类的主要任务是构造分类器，需要有一个训练样本数据集作为输入。分类的目的是分析输入数据，为每个类找到一种准确的描述或者模型。
   - ***<u>序列挖掘</u>***：是指**数据库中发现相对时间或者其他顺序出现的高频率子序列**。
   - ***<u>聚类</u>***：就是**将数据对象分组成为多个类或簇**。划分的原则是在同一个簇中的对象之间具有较高的相似度，而不同簇中的对象差别较大。与分类不同的是，聚类操作中要划分的类是事先未知的，类的形成完全是数据驱动的，属于一种无指导的学习方法。
   - **<u>*层次聚类法*</u>**：是对给定数据对象集合**进行层次的分解**。其基本思想是将数据样本**按照距离准则逐步聚类，直至满足分类要求为止**。一般分为凝聚的和分裂的两种方案。
   - **<u>*时间序列数据挖掘*</u>**：就是要**从大量的时间序列数据中提取人们事先不知道的、但又是潜在有用的与时间属性相关的信息和知识**。并用于短期、中期或长期预测，知道人们的社会、经济、军事和生活等行为。
   - **<u>*后验概率*</u>**：又称条件概率，是**在已知结果发生的情况下，求导致结果的某种原因的可能性的大小**。
   - **<u>*数字地球*</u>**：是一种**关于地球的可以嵌入海量地理数据的、多分辨率的和三维的表示**，它提供一种机制引导用户寻找地理信息，可供出版者出版。

2. 补充

   - **<u>*机器学习（Machine Learning）*</u>**：研究**如何使用机器来模拟人类学习活动**的一门学科。
   
   - **<u>*人工神经网络（Artificial Neural Networks，ANNs）*</u>**：**简称神经网络**（NNs），是一种**模仿动物神经网络行为特征**，进行**分布式并行信息处理**的算法数学模型。
   
   - **<u>*人工智能（Artificial Intelligence）*</u>**：研究如何应用机器来**模拟人类某些智能行为**的基本理论、方法和技术的一门科学。
   
   - **<u>*大数据（Big Data）*</u>**：指一种**规模大到在获取、存储、管理、分析方面**大大**超出了传统数据库软件工具能力范围**的数据集合。（特征是）海量的数据规模、快速的数据流转、多样的数据类型和价值密度低。
   
   - **<u>*知识工程（Knowledge Engineering）*</u>**：研究**知识信息处理**并**探讨开发知识系统**的技术。
   
   - **<u>*广义知识（Generalization）*</u>**：描述**类别特征**的概括性知识。这类数据挖掘系统是对细节数据所蕴涵的概念特征信息的概括和抽象的过程。
   
   - **<u>*关联知识（Association）*</u>**：**反映**⼀个事件和其他事件之间的**依赖或关联**。目的是找出数据库中**隐藏的关联信息**。
   
   - **<u>*爬虫（spider/crawler）*</u>**：是一种按照一定的规则，**自动地抓取万维网信息的程序或者脚本**。
   
   - **<u>*数据仓库（Data Warehouse）*</u>**：是决策支持系统（dss）和联机分析**应用数据源的结构化数据环境**。数据仓库**研究和解决**从数据库中**获取信息的问题**。数据仓库的特征在于**面向主题、集成性、稳定性和时变性**。
   
   - **<u>*OLTP（On-Line Transaction Processing）*</u>**：**联机事务处理传统的关系型数据库的主要应用**，主要是基本的、日常的**事务处理**（增删改查），例如银行交易。
   
   - **<u>*OLAP（On-Line Analytic Processing）*</u>**：**联机分析处理数据仓库系统的主要应用**，支持**复杂的分析操作**，侧重**决策支持**，并且提供直观易懂的查询结果 。
   
   - **<u>*决策支持（Decision Support）*</u>**：决策者通过数据、模型和知识，以**人机交互方式**进行**半结构化或非结构化决策**。
   
   - **<u>*事务数据库（Transaction Database）*</u>**：一个**事务数据库**是对**事务型数据的收集**。
   
   - **<u>*分布式数据库（Distributed Database）*</u>**：**物理上分散**而**逻辑上集中**的数据库系统。

------



### 知识发现过程

1. 知识发现（Knowledge Discovery in Database，KDD）★

   - 定义：是一个**系统化**的工作，必须**对可以利用的源数据进行分析**，**确定合适的挖掘目标**，然后才能着手系统的设计和开发。KDD是一个多步骤的处理过程，一般分为**问题定义、数据采集、数据预处理、数据挖掘、模式评估**等基本阶段。
   - 过程
     1. 首先从数据源中**抽取感兴趣的数据**，并把它**组织成适合挖掘的数据组织形式**；
     2. 然后**调用相应的算法**生成所需的知识；
     3. 最后对生成的知识模式**进行评估**，并把有价值的知识集成到企业的智能系统中。
   - 基本阶段的特点
     - ***<u>问题定义阶段</u>***：KDD是用于在大量数据中**发现有用的令人感兴趣的信息**，因此发现何种知识就成为整个过程中第一个也是最重要的一个阶段。
     - **<u>*数据抽取阶段*</u>**：目的是**选取相应的源数据库**，并**根据要求**从数据库中**提取相关的数据**。 
     - **<u>*数据预处理阶段*</u>**：主要对前一阶段抽取的数据**进行再加工**，**检查数据的完整性及数据的一致性**，包括消除噪声、推导计算缺值数据、消除重复记录、完成数据类型转换（如把连续值变成离散值，以便符号归纳等）。
     - **<u>*数据挖掘阶段*</u>**：**运用选定的数据挖掘算法**，从数据中**提取出用户需要的知识**。
     - **<u>*知识评估阶段*</u>**：数据挖掘阶段发现出来的模式，经过评估，**可能存在冗余或无关的模式**，这需要将其**剔除**；也有可能**不满足用户的需求**，这需要将整个发现过程**回退到前续阶段**。如重新选取数据、采用新的数据变换方法等。知识评估是KDD一个重要的必不可少的阶段。

2. 阶梯处理过程模型★

   - 基本处理流程图示

     <img src="assets\KDD阶梯处理过程模型.png" alt="KDD阶梯处理过程模型" style="zoom:50%;" />

   - 定义：阶梯处理过程模型将数据库中的知识发现看作是一个**多阶段的处理过程**，在整个知识发现的过程中包括很多处理阶段。**主要有九个处理阶段**，这九个处理阶段分别是**数据准备、数据选择、数据预处理、数据缩减、KDD目标确定、挖掘算法确定、数据挖掘、模式解释**及**知识评价**。

   - 处理阶段

     - **<u>*数据准备*</u>**：了解KDD相关领域的有关情况，熟悉有关的背景知识，并弄清楚用户的要求，**确定挖掘的总体目标和方法**。了解相关的源数据结构并加以分析，**确定数据选择的原则**。
     - **<u>*数据选择*</u>**：**根据用户的要求**从数据库中**提取与KDD目标相关的数据**。在此过程中，KDD系统将从备选的源数据中进行知识提取。这种数据选择工作可以借助于数据库操作语言或专门的工具来进行。
     - **<u>*数据预处理*</u>**：主要是对上一阶段产生的数据**进行再加工**，**检查数据的完整性及数据的一致性**，对其中的**噪声数据进行处理**，对**丢失的数据**可以利用统计方法**进行填补**。对一些**不适合于操作**的数据**进行必要的处理**等。
     - **<u>*数据缩减*</u>**：对经过预处理的数据，根据知识发现的任务对数据**进行必要的再处理**，**使数据集中在用户的挖掘目标上**。此过程对KDD系统的精度和效率起着至关重要的作用。它也可以通过数据库中的投影等相关操作或专门的工具来完成。
     - **<u>*KDD目标确定*</u>**：**根据挖掘的目标和用户的要求**，**确定**KDD所发现的**具体知识模式和类型**，为选择或开发适合用户要求的数据挖掘算法提供模式或模板。
     - **<u>*挖掘算法确定*</u>**：根据上一阶段所确定的模式，**选择合适的数据挖掘算法**，这包括选取合适的参数、知识表示方式，并保证数据挖掘算法与整个KDD的评判标准相一致。
     - **<u>*数据挖掘*</u>**：**运用选定的算法**，从数据中**提取出用户所需要的知识**。这些知识可以用一种特定的方式表示或使用一些常用的表示方式，如产生式规则等。
     - **<u>*模式解释*</u>**：**对发现的模式进行解释**。在此过程中，为了取得更为有效的知识，可能会返回前面处理步骤中的某些步以改进结果，保证提取出的知识是有效的和可用的。
     - **<u>*知识评价*</u>**：**将发现的知识以用户能了解的方式呈现给用户**。这期间也包含对知识的一致性的检查，以确信本次发现的知识与以前发现的知识不相抵触。

------



### 关联规则挖掘

1. 项目集格空间理论★

   - 核心原理
     - 频繁项目集的**非空子集**都是频繁项目集。
     - 非频繁项目集的**超集**都是非频繁项目集。

2. 事务数据库中关联规则挖掘★

   - 主要步骤
     1. **<u>*挖掘频繁项集*</u>**
        - 主要任务：在事务数据库中**找到频繁项集**，即在数据集中经常同时出现的项的集合。
        - 目标：**识别出**在数据集中**频繁出现的项集**，这些项集的支持度（Support）**大于或等于预先设定的最小支持度阈值**。
     2. **<u>*生成关联规则*</u>**
        - 主要任务：基于频繁项集，生成**满足最小置信度阈值**的关联规则。
        - 目标：**发现**项集之间的**关联规则**，以确定项集 A 的出现是否可能导致项集 B 的出现。

3. Apriori算法★

   - 定义：是一种**挖掘关联规则**的**频繁项集算法** ，其核心思想是通过**候选集生成**和**情节的向下封闭检测**两个阶段来挖掘频繁项集。

   - 算法步骤

     ![Apriori算法执行步骤](assets\Apriori算法执行步骤.png)
     
   - 伪代码

     1. <u>***发现频繁项目集***</u>

       - 输入：数据集D；最小支持度minsup_count
       - 输出：频繁项目集L

       <img src="assets\Apriori-发现频繁项目集.jpg" alt="Apriori-发现频繁项目集" style="zoom: 50%;" />

     2. **<u>*候选集产生*</u>**

       - 输入：(k-1)-频繁项目集Lk-1

       - 输出：k-候选项目集Ck

         <img src="assets\Apriori-候选集产生.jpg" alt="Apriori-候选集产生" style="zoom: 67%;" />

   - 例题

     见课本P76-79

4. Close算法

   - 目的：**减少搜索空间**和**提高挖掘效率**。

   - 优点：Close 算法的**优势**在于它的**剪枝操作**，它能够**减少不必要的搜索**，提高了关联规则挖掘的效率。

   - 闭合项目集：一个项目集C，当且仅当对于在C中的任何元素，不可能在C中存在小于或等于它的支持度的子集。或者A的**闭合项集**是指所有包含A的**项目的交集**，**支持度**是指包含A的项目的**交集出现的频数**。

     <img src="assets\Close-闭合项集.png" alt="Close-闭合项集" style="zoom:67%;" />

   - 算法步骤
     1. **<u>*初始化*</u>**：
        - 生成所有单个项的频繁项集。
        - 对频繁项集按照字典序排序。
     2. **<u>*迭代生成频繁项集*</u>**：
        - 从长度为 k-1 的频繁项集中生成长度为 k 的候选项集。
        - 对候选项集进行剪枝，移除非频繁的项。
        - 对剩余的候选项集进行扩展，生成新的频繁项集。
        - 对新生成的频繁项集按照字典序排序。
     3. **<u>*判断是否终止*</u>**：
        - 如果没有生成更多频繁项集，则算法终止。
        - 否则，回到步骤 2。
     4. **<u>*提取关联规则*</u>**：
        - 对于每个频繁项集，生成其所有非空子集。
        - 对每个子集，计算其支持度。
        - 利用支持度和信任度等指标提取关联规则。
     
   - 算法关键点

     - **<u>*剪枝操作*</u>**：Close 算法引入了剪枝操作，以去除非频繁项，减少搜索空间。
     - **<u>*按字典序排序*</u>**：对生成的频繁项集按字典序排序，确保结果的一致性。
     - **<u>*频繁项集的生成*</u>**：使用候选项集的扩展和剪枝来生成新的频繁项集。

   - 伪代码

     ![Close-伪代码](assets\Close-伪代码.jpg)

   - 例题

     见课本P86-88

5. FP-tree算法

   - 优势：只进行**两次数据库扫描**。它**不使用候选集**，直接压缩数据库成一个**频繁模式树**，最后通过这棵树生成关联规则。

   - 主要步骤

     1. <u>***利用事务数据库中的数据构造FP-tree***</u>

        说明：在FP-tree构造过程中，总是尽量将出现**频度高的项目放在靠近根结点**。

        1. 首先扫描数据库一次生成1-频繁集，并将它们按降序排序，放入L表中。
        2. 再扫描数据库一次，对每个数据库的元组，把它对于项目集的关联和频度信息放入到FP-tree中。

     2. <u>***从FP-tree中挖掘频繁模式***</u>

        说明：用FP-tree挖掘频繁集的基本思想是**分而治之**。

        1. 对每个项，生成它的条件模式集（一个“子数据库”，由FP-tree中与后缀模式一起出现的前缀路径集组成），然后是它的条件FP-tree。
        2. 对每个新生成的条件FP-tree，重复这个步骤。
        3. 直到结果FP-tree为空，或只含唯一的一个路径（此路径的每个子路径对应的项目集都是频繁集）

------



### 分类方法

1. 定义：分类是一种**监督学习**，即每个训练样本的数据对象己经有类标识，通过学习可以形成表达数据对象与类标识间对应的知识。

2. 目的：利用历史数据纪录来**自动学习一个分类模型/函数（分类器）**，利用该模型把数据库中的**数据项映射到给定类别中的某一个类别**，从而能对未来数据进行类别预测。

3. 基于距离的分类方法（KNN算法）★

   - 定义：KNN通过计算每个**训练数据到待分类元组的距离**，取和待分类元组距离最近的K个训练数据，K个数据中**哪个类别的训练数据占多数**，则待分类元组就**属于哪个类别**。

   - 算法步骤

     1. **<u>*收集数据*</u>**：
        - 收集带有标签的训练数据，其中每个样本都有一个类别标签。
     2. **<u>*选择K值*</u>**：
        - 选择要用于分类的邻居数量（K值）。K值的选择通常通过交叉验证来确定。
     3. **<u>*计算距离*</u>**：
        - 对于给定的未标记样本，计算它与训练集中每个已标记样本之间的距离。常用的距离度量包括欧氏距离、曼哈顿距离、闵可夫斯基距离等。
     4. **<u>*找到K个最近邻*</u>**：
        - 选择与未标记样本距离最近的K个训练样本。
     5. **<u>*投票决策*</u>**：
        - 对于分类问题，统计K个最近邻中每个类别的出现次数。未标记样本被赋予与其最近邻中出现最多的类别。

   - 伪代码

     - 输入：训练数据T；近邻数目K；待分类的元组t。
     - 输出：输出类别c

     <img src="assets\KNN-伪代码.jpg" alt="KNN-伪代码" style="zoom:50%;" />

   - 例题

     见课本P126-127

4. 决策树分类方法（ID3算法，C4.5算法）

   - ID3算法

     - 信息熵：是**对随机变量不确定度的度量**，熵越大，随机变量的不确定性就越大。

       <img src="assets\ID3-信息熵.png" style="zoom:67%;" />

     - 信息增益：**针对一个特征**而言的，就是看一个特征，系统有它和没有它时的信息量各是多少，两者的差值就是这个特征给系统带来的信息量，即信息增益。

       <img src="assets\ID3-信息增益.png" alt="ID3-信息增益" style="zoom:67%;" />

     - 算法步骤

       1. **<u>*选择最佳特征*</u>**：
          - 计算每个特征的信息增益（或信息增益比、基尼指数等）。
          - 选择信息增益最大的特征作为当前节点的分裂特征。
       2. **<u>*将数据集划分*</u>**：
          - 使用选定的分裂特征将数据集划分为子集，每个子集对应于该分裂特征的一个取值。
       3. **<u>*递归构建子树*</u>**：
          - 对于每个子集，重复步骤1和步骤2，递归构建子树。
          - 如果子集纯净（属于同一类别）或达到预定的树深度或停止条件，则停止递归。
       4. **<u>*构建决策树*</u>**：
          - 将选择的分裂特征作为当前节点的特征。
          - 对于每个子集，将其递归构建的子树作为当前节点的子树。
       5. **<u>*停止条件*</u>**：
          - 构建树的过程中，可以设置一些停止条件，如达到预定的树深度、子集纯净度达到阈值等。

     - 伪代码

       ![ID3-伪代码](assets\ID3-伪代码.jpg)

     - 例题

       见课本P131-132

   - C4.5算法

     - 相对ID3增加的新功能

       - 用**信息增益比例**的概念
       - 合并具有**连续属性**的值
       - **可以处理缺少属性值**的训练样本
       - 通过使用**不同的修剪技术**以避免树的过拟合
       - **k交叉验证**
       - 规则的产生方式

     - 信息增益比例

       <img src="assets\C4.5-信息增益比例.png" alt="C4.5-信息增益比例" style="zoom:67%;" />

       <img src="assets\C4.5-信息增益比例SplitI.png" alt="C4.5-信息增益比例SplitI" style="zoom:67%;" />

     - 例题

       见课本P136-138

   - 两者的异同★

     - 相同点：
       - 都是**基于信息熵的决策树算法**，都采用**自顶向下的贪心策略**。
       - 都是通过对数据集进行**递归划分**，生成决策树模型。
       - 都可以**处理离散型数据和连续型数据**。

     - 不同点：

       - **ID3算法使用信息增益**来选择最优特征，而**C4.5算法使用信息增益率**来选择最优特征。信息增益率在信息增益的基础上，对可取值数目较少的特征有所偏好，**避免了信息增益选择特征时偏向取值较多的特征的问题**。

       - **C4.5算法可以处理缺失值**，而ID3算法不能。

       - **C4.5算法使用后剪枝来避免过拟合**，而ID3算法没有使用后剪枝。

5. 贝叶斯分类（朴素贝叶斯算法）

   - 基本思想

     - 贝叶斯定理：贝叶斯定理描述了在**给定先验知识**的情况下，如何通过新的观测数据来**更新对一个事件的概率**估计。
     - 朴素假设：朴素贝叶斯算法假设样本的特征之间相互独立，即**给定类别，特征之间不存在依赖关系**。

   - 例题

     见课本P140-143


------



### 聚类方法

1. 定义：把一组个体**按照相似性归为若干类别**。聚类属于**无监督学习**。

2. 目的：使**同一类别**的个体之间的**差别尽可能地小**，**不同类别**上的个体间的**差别尽可能地大**。

3. 评价准则

   - **类间**距离**大**，即不同簇的数据尽量**不相似**。
   - **类内**距离**小**，即一个簇内的数据尽量**相似**。

4. 距离函数

   - 距离条件

     - 非负性
     - 对称性
     - 三角不等式

   - 明可夫斯基距离

     <img src="assets\明可夫斯基距离.png" alt="明可夫斯基距离" style="zoom:67%;" />

   - 曼哈顿距离（绝对值距离）

     <img src="assets\曼哈顿距离.png" alt="曼哈顿距离" style="zoom:67%;" />

   - 欧氏距离

     <img src="assets\欧氏距离.png" alt="欧氏距离" style="zoom:67%;" />

   - 切比雪夫距离

     <img src="assets\切比雪夫距离.png" alt="切比雪夫距离" style="zoom:67%;" />

   - 余弦距离

     <img src="assets\余弦距离.png" alt="余弦距离" style="zoom:67%;" />

5. 划分聚类方法（k-means算法，k-medoids算法）

   - 主要思想

     - 每一个簇至少包含一个对象
     - 每一个对象属于且**仅**属于一个簇
     
   - 簇的表现形式

     - 通过它们的**中心**或者**类中关系远的（边界）点**表示空间的一类点
   - 使用聚类树中的结点**图形化**地表示一个类
     - 使用样本属性的**逻辑表达式**表达类

   - k-means算法★

     - 定义：也被称为**k-均值**，是一种被广泛使用的聚类算法。k-平均算法以k为参数，把n个对象分为k个簇，以使**簇内具有较高的相似度**。相似度的计算根据一个簇中的**对象的平均值**来进行。

     - 算法描述

       1. 给定集合D，有**n个样本点**
       2. **随机指定k个点**，**作为**k个子集的**质心**
       3. 根据样本点与k个质心的**距离远近**，将每个样本点**划归最近质心所在的子集**
       4. 对k个子集**重新计算质心**
       5. 根据新的质心，重复操作3.
       6. 重复操作4.和5.，**直至结果足够收敛或者不再变化**

     - 伪代码

       <img src="assets\k-means-伪代码.jpg" alt="k-means-伪代码" style="zoom: 80%;" />

     - 性能分析

       - 主要优点
         - 是解决聚类问题的一种经典算法，**简单、快速**。
         - 对处理大数据集，该算法是相对**可伸缩和高效率**的。
         - 当**结果簇是密集的**，它的**效果较好**。
       - 主要缺点
         - 在簇的**平均值被定义**的情况下**才能使用**，可能不适用于某些应用。
         - 必须**事先给出k**（要生成的簇的数目），而且**对初值敏感**，对于不同的初始值，可能会导致不同结果。
         - **不适合**于发现**非凸面形状的簇**或者**大小差别很大的簇**。对于**“噪声”和孤立点数据**是**敏感**的。

     - 例题

       见课本P181-182

   - k-medoids算法
     - 定义：K 中心点算法中，每次迭代后的质点都是从**聚类的样本点中选取**，k中心点算法不采用簇中对象的平均值作为簇中心，而选用簇中**离平均值最近的对象**作为簇中心。这样划分方法仍然是基于最小化所有对象与其参照点之间的相异度之和的原则来执行的。

6. 层次聚类算法（AGNES算法，DIANA算法）

   - 定义：层次聚类方法对给定的数据集**进行层次的分解**，**直到满足某种条件为止**。具体又可分为**凝聚的、分裂的两种方案**。

     - **<u>*凝聚的层次聚类*</u>**是一种**自底向上**的策略，首先**将每个对象作为一个簇**，然后**合并这些原子簇**为越来越大的簇，直到所有的对象都在一个簇中，或者某个终止条件被满足，绝大多数层次聚类属于这一类，他们只是在簇间相似度的定义上有所不同。
     - **<u>*分裂的层次聚类*</u>**与凝聚的层次聚类相反，采用**自顶向下**的策略，它首先**将所有对象置于一个簇**，然后**逐渐细分为越来越小的簇**，直到每个对象自成一簇，或者达到了某个终结条件。

   - AGNES算法

     - 定义：**自底向上凝聚的算法**，先**将每个对象作为一个簇**，然后这些簇**根据某些准则**（类间距离最近的两个点）被**一步步地合并**，直到某个终结条件被满足（达到定义的簇的数目）。两个簇间的相似度由这两个不同簇中**距离最近的数据点对的相似度来确定**。

     - 伪代码

       输入：包含n个对象的数据库，终止条件簇的数目k。
       输出：k个簇，达到终止条件规定簇数目。

       1. 将每个对象当成一个初始簇；
       2. REPEAT
       3. 根据两个簇中最近的数据点的距离找到最近的两个簇；
       4. 合并两个簇，生成新的簇的集合；
       5. UNTIL 达到定义的簇的数目；

     - 例题

       见课本P189-190

   - DIANA算法

     - 定义：**自顶向下分裂的算法**，它首先将**所有对象置于一个簇**中，然后**逐渐细分**为越来越小的簇，直到达到了某个终结条件（达到了某个希望的簇数目，或两个最近簇之间的距离超过了某个阈值）。

     - 簇的直径：在一个簇中的**任意两个数据点**的**欧氏距离中的最大值**。

     - 平均相异度（平均距离）

       <img src="assets\DIANA-平均相异度.png" alt="DIANA-平均相异度" style="zoom:67%;" />

     - 伪代码

       - 输入：包含n个对象的数据库，终止条件簇的数目k。
       - 输出：k个簇，达到终止条件规定簇数目。

       <img src="assets\DIANA-伪代码.jpg" alt="DIANA-伪代码" style="zoom: 50%;" />

     - 例题

       见课本P191-192
     
   - 两者的异同★

     - 相同点
       - AGNES 和 DIANA **都属于层次聚类算法**，这意味着它们通过递归地划分或合并簇，构建一个层次结构，形成一个聚类树（或树状图）。
       - **都需要定义簇间的距离度量或相似性度量**，以确定合并或分裂的标准。
       - AGNES 和 DIANA **都能够形成一个树状结构**，其中每个节点代表一个簇，边表示合并或分裂的过程。
       - 两者**都无需事先指定聚类数目**，而是通过合并或分裂的过程自适应地形成不同层次的簇。

     - 不同点

       - **AGNES 采用自底向上**的策略，**DIANA 采用自顶向下**的策略。

       - **AGNES 的计算复杂度相对较高**，因为在每一步都需要计算所有簇对之间的距离。DIANA 在初始时计算较少的距离，但递归过程中可能需要计算的距离逐渐增多。
       - **AGNES 对于缺失值较为敏感**，因为在计算簇间距离时，需要考虑所有数据点的距离。DIANA 对于缺失值的影响相对较小，因为它主要关注簇内的距离。

7. 密度聚类方法（DBSCAN算法）

   - 指导思想：只要有一个区域中，**点的密度大于某个阈值**，就把它**加到与之相连的簇**中去。

   - 噪声点：不包含在任何簇中的对象被认为是“噪声”。

   - 边界点：落在某个核心点的邻域内，是一个稠密区域边缘上的点。（非核心对象点）

   - 阈值：包含多于MinPts个对象

   - 定义：DBSCAN是**噪声环境**下的**密度聚类算法**，将密度相连的点的**最大集合聚成簇**，并可在有“噪声”的空间数据库中发现任意形状的聚类。

   - 特点：事先不知道会有多少个簇

   - 相关概念

     <img src="assets\DBSCAN-相关概念1.jpeg" alt="DBSCAN-相关概念1" style="zoom: 80%;" />

     <img src="assets\DBSCAN-相关概念2.jpeg" alt="DBSCAN-相关概念2" style="zoom:80%;" />

   - **步骤：**

     1. 先找到核心对象
     2. 找簇中的直接密度可达
     3. 在直接密度可达点中密度可达点（已经被包含在其他簇的点不用加入）
   
   - 算法描述

     1. DBSCAN通过检查数据集中每点的Eps领域来搜索簇，如果一个点q的区域内包含多于MinPts个对象，则创建一个q作为核心对象的簇。
     2. 然后，反复地从这些核心对象中寻找直接密度可达的对象，把一些密度可达簇进行合并。
     3. 当没有新的点可以被添加到任何簇时，该过程结束。
   
   - 伪代码
   
     - 输入：包含n个对象的数据库，半径ε，最少数目MinPts。
     - 输出：所有生成的簇，达到密度要求。
   
     1. REPEAT
     2. 从数据库中抽取一个未处理过的点；
     3. IF 抽出的点是核心点 THEN找出所有从该点密度可达的对象，形成一个簇
     4. ELSE 抽出的点是边缘点(非核心对象)，跳出本次循环，寻找下一点；
     5. UNTIL 所有点都被处理；
   
   - 性能分析
   
     - 优点
       - 聚类**速度快**且能够**有效处理噪声点**和**发现任意形状的空间聚类**；
       - 与K-MEANS比较起来，**不需要输入要划分的聚类个数**；
       - 聚类簇的**形状没有偏倚**；
       - **对噪声数据不敏感**。
     - 缺点
       - 当**数据量增大**时，要求**较大的内存支持I/O消耗也很大**；
       - 当空间聚类的**密度不均匀**、聚类间**距差相差很大**时，聚类**质量较差**，因为这种情况下参数MinPts和 ϵ 选取困难（对半径和Minpoints敏感）。
       - 算法聚类效果**依赖与距离公式选取**， 实际应用中常用欧式距离，对于高维数据，存在“维数灾难”。
   
   - 例题
   
     见课本P195-196


------



### 时间序列挖掘技术

1. 时间序列挖掘的含义★：就是要从大量的时间序列数据中**提取人们事先不知道的**、但又是**潜在有用的与时间属性相关的**信息和知识。
2. 时间序列挖掘的意义★：
   - 用于短期、中期或长期预测等**决策性工作**，**指导**人们的**社会、经济、军事和生活**等行为。
   - 时间序列数据挖掘通过**研究信息的时间特性**，**深入洞悉事物进化的机制**，是**获得知识的有效途径**。
3. 时间序列的分类★：
   - **<u>*绝对数时间序列*</u>**：由时期总量指标排列而成的时间序列。
   - **<u>*相对数时间序列*</u>**：把一系列同种相对数指标按时间先后顺序排列而成的时间序列叫做相对数时间序列。
   - **<u>*平均数时间序列*</u>**：平均数时间序列是指由一系列同类平均指标按时间先后顺序排列的时间序列。
4. 时间序列挖掘的主要任务★：
   - 时间序列相似性搜索
   - 时间序列聚类
   - 时间序列分类
   - 时间序列分割与模式发现
   - 海量时间序列可视化
   - 时间序列预测
5. 应用场景：时间序列挖掘在**宏观的经济预测、市场营销、客流量分析、太阳黑子数、月降水量、河流流量、股票价格变动等**众多领域得到应用。事实上，**社会、科学、经济、技术等领域**中广泛存在着大量的时间序列数据有待进一步的分析和处理。

<!--注意：3-4均来源于chatGPT-->

------



### Web挖掘技术

1. Web挖掘的意义★

   - 从大量的信息中**发现用户感兴趣的信息**
   - 将Web上的丰富信息**转变成有用的知识**
   - 对用户**进行信息个性化**

2. Web挖掘的分类★

   - **<u>*Web内容挖掘*</u>**：对站点的Web页面的各类 信息进行集成、概化、分类等，挖掘某类信息所蕴含的知识模式。
   - **<u>*Web访问信息挖掘*</u>**：Web访问信息挖掘是对 用户访问Web时在服务器方留下的访问记录进行挖掘。通过分析日 志记录中的规律，可以识别用户的忠实度、喜好、满意度，可以 发现潜在用户，增强站点的服务竞争力。
   - **<u>*Web结构挖掘*</u>**：Web结构挖掘是对Web页 面之间的链接结构进行挖掘。在整个Web空间里，有用的知识不仅 包含在Web页面的内容之中，而且也包含在页面的链接结构之中。 对于给定的Web页面集合，通过结构挖掘可以发现页面之间的关联 信息，页面之间的包含、引用或者从属关系等。

3. Web挖掘的含义★：是**数据挖掘在Web上的应用**，它**利用数据挖掘技术**从与WWW相关的资源和行为中**抽取感兴趣的、有用的模式和隐含信息**。

4. Web挖掘的主要数据源

   - Web服务器**日志**数据
   - Web上的**电子商务**数据
   - Web上的**网页**
   - Web上的网页之间的**链接**
   - Web上的**多媒体**数据

5. PageRank算法★

   - 核心思想

     - 如果**一个网页被很多其他网页链接到**的话说话这个网页比较重要，也就是**PageRank值会相对较高**。
     - 如果**一个PageRank值很高的网页链接到一个其他的网页**，那么**被链接到的网页的PageRank值**会相应地因此而**提高**。

   - 算法步骤

     1. 计算每个网页一个PageRank（PR）值
     2. 通过（投票）算法不断迭代，直至达到平稳分布为止。
     3. 根据这个值的大小对网页的重要性进行排序。

     概括：计算每一个网页的PageRank值，然后根据这个值的大小对网页的重要性进行排序。

   - 基于随机冲浪的PageRank算法

     - 伪代码

       <img src="assets\基于随机冲浪的PageRank-伪代码.png" alt="基于随机冲浪的PageRank-伪代码" style="zoom: 33%;" />

     - 例题

       见课本P327-329

6. 权威页面和中心页面

   - **<u>*权威页面*</u>**：是指**包含需求信息的最佳资源页面**。是指**与某个领域或者某个话题相关的高质量网页**，比如搜索引擎领域，Google和百度首页即该领域的高质量网页，比如视频领域，优酷和土豆首页即该领域的高质量页面。
   - **<u>*中心页面*</u>**：是一个**包含权威页面链接的页面**。

------



### 空间数据挖掘技术

1. 空间挖掘的含义★：也称作空间数据挖掘，或者空间数据库的知识发现。空间挖掘就是从**空间数据库**等空间数据中**挖掘隐含的知识模式**，包括空间相关的基于空间的关联关系、聚类分类等模式，**用于理解和归纳空间数据。**

2. 空间挖掘的意义★：

   - **<u>*帮助理解空间数据*</u>**：通过挖掘空间数据，可以揭示地理空间中存在的模式和关系，帮助人们更好地理解空间数据。
   - **<u>*地理决策支持*</u>**：在城市规划、资源管理、环境保护等领域，空间数据挖掘可以为决策提供有力的支持。
   - **<u>*预测和规划*</u>**：通过挖掘历史空间数据，可以预测未来的趋势，并为规划提供参考。
   - **<u>*应用于导航和位置服务*</u>**：空间数据挖掘对于导航、位置服务和地理信息系统等应用具有重要价值。

   总结：空间数据挖掘实质上是**空间信息技术发展的必然结果**。

3. 空间挖掘的分类★：

   - **<u>*空间关系挖掘*</u>**：发现不同地理实体之间的空间关系，如邻近、重叠、包含等。
   - **<u>*空间模式挖掘*</u>**： 发现在空间数据中出现的模式，如簇、群集、异常点等。
   - **<u>*空间序列挖掘*</u>**：结合时间信息，挖掘地理空间中随时间变化的模式和趋势。
   - **<u>*地理数据分类与聚类*</u>**：将地理空间数据进行分类和聚类，以识别不同地理区域或类型。

4. 空间挖掘的主要任务★：

   - 空间关系分析
   - 空间模式发现
   - 轨迹分析
   - 地理数据分类与聚类
   - 地理数据可视化

<!--注意：2-4均来源于chatGPT-->
